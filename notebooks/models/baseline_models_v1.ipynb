{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9277872",
   "metadata": {},
   "source": [
    "# Forecasting Delays in the Swiss Transportation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee97ae",
   "metadata": {},
   "source": [
    "## Establishing Baseline Models with Engineered Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921479c",
   "metadata": {},
   "source": [
    "Copyrights © 2025, 2026 Yvan Richard.  \n",
    "All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac250d",
   "metadata": {},
   "source": [
    "## Foreword\n",
    "\n",
    "In this notebook, I rapidly try some basic baseline models on the engineered data set. Since the missing values are very sparse, I'll use a complete case analysis for this baseline. This approach will be further assessed in the error analysis part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4403f6",
   "metadata": {},
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a601b580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2.89% rows with missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_date</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>line_name</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>additional_trip</th>\n",
       "      <th>arrival_scheduled_dt</th>\n",
       "      <th>arrival_observed_dt</th>\n",
       "      <th>arrival_delay_minutes</th>\n",
       "      <th>...</th>\n",
       "      <th>vt_RJX</th>\n",
       "      <th>vt_S</th>\n",
       "      <th>vt_SN</th>\n",
       "      <th>vt_TER</th>\n",
       "      <th>vt_TGV</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>connection_density</th>\n",
       "      <th>running_trip_delay</th>\n",
       "      <th>mean_stop_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>ch:1:sjyid:100001:19220-001</td>\n",
       "      <td>8506013</td>\n",
       "      <td>Aadorf</td>\n",
       "      <td>S12</td>\n",
       "      <td>S</td>\n",
       "      <td>false</td>\n",
       "      <td>2025-01-03 05:31:00</td>\n",
       "      <td>2025-01-03 05:30:55</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>47.488118</td>\n",
       "      <td>8.903301</td>\n",
       "      <td>35</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>ch:1:sjyid:100001:19219-002</td>\n",
       "      <td>8506013</td>\n",
       "      <td>Aadorf</td>\n",
       "      <td>S12</td>\n",
       "      <td>S</td>\n",
       "      <td>false</td>\n",
       "      <td>2025-01-03 06:28:00</td>\n",
       "      <td>2025-01-03 06:28:41</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>47.488118</td>\n",
       "      <td>8.903301</td>\n",
       "      <td>35</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>ch:1:sjyid:100001:19224-001</td>\n",
       "      <td>8506013</td>\n",
       "      <td>Aadorf</td>\n",
       "      <td>S12</td>\n",
       "      <td>S</td>\n",
       "      <td>false</td>\n",
       "      <td>2025-01-03 06:31:00</td>\n",
       "      <td>2025-01-03 06:31:04</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>47.488118</td>\n",
       "      <td>8.903301</td>\n",
       "      <td>35</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.605556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>ch:1:sjyid:100001:19223-002</td>\n",
       "      <td>8506013</td>\n",
       "      <td>Aadorf</td>\n",
       "      <td>S12</td>\n",
       "      <td>S</td>\n",
       "      <td>false</td>\n",
       "      <td>2025-01-03 07:28:00</td>\n",
       "      <td>2025-01-03 07:29:28</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>47.488118</td>\n",
       "      <td>8.903301</td>\n",
       "      <td>35</td>\n",
       "      <td>2.272222</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>ch:1:sjyid:100001:19228-001</td>\n",
       "      <td>8506013</td>\n",
       "      <td>Aadorf</td>\n",
       "      <td>S12</td>\n",
       "      <td>S</td>\n",
       "      <td>false</td>\n",
       "      <td>2025-01-03 07:31:00</td>\n",
       "      <td>2025-01-03 07:31:08</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>47.488118</td>\n",
       "      <td>8.903301</td>\n",
       "      <td>35</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.738889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     op_date                      trip_id  stop_id stop_name line_name  \\\n",
       "1 2025-01-03  ch:1:sjyid:100001:19220-001  8506013    Aadorf       S12   \n",
       "2 2025-01-03  ch:1:sjyid:100001:19219-002  8506013    Aadorf       S12   \n",
       "3 2025-01-03  ch:1:sjyid:100001:19224-001  8506013    Aadorf       S12   \n",
       "4 2025-01-03  ch:1:sjyid:100001:19223-002  8506013    Aadorf       S12   \n",
       "5 2025-01-03  ch:1:sjyid:100001:19228-001  8506013    Aadorf       S12   \n",
       "\n",
       "  vehicle_type additional_trip arrival_scheduled_dt arrival_observed_dt  \\\n",
       "1            S           false  2025-01-03 05:31:00 2025-01-03 05:30:55   \n",
       "2            S           false  2025-01-03 06:28:00 2025-01-03 06:28:41   \n",
       "3            S           false  2025-01-03 06:31:00 2025-01-03 06:31:04   \n",
       "4            S           false  2025-01-03 07:28:00 2025-01-03 07:29:28   \n",
       "5            S           false  2025-01-03 07:31:00 2025-01-03 07:31:08   \n",
       "\n",
       "   arrival_delay_minutes  ...  vt_RJX  vt_S  vt_SN  vt_TER  vt_TGV   latitude  \\\n",
       "1              -0.083333  ...   False  True  False   False   False  47.488118   \n",
       "2               0.683333  ...   False  True  False   False   False  47.488118   \n",
       "3               0.066667  ...   False  True  False   False   False  47.488118   \n",
       "4               1.466667  ...   False  True  False   False   False  47.488118   \n",
       "5               0.133333  ...   False  True  False   False   False  47.488118   \n",
       "\n",
       "   longitude  connection_density  running_trip_delay  mean_stop_delay  \n",
       "1   8.903301                  35            0.150000         1.216667  \n",
       "2   8.903301                  35            0.577778         0.566667  \n",
       "3   8.903301                  35            0.994444         0.605556  \n",
       "4   8.903301                  35            2.272222         0.375000  \n",
       "5   8.903301                  35            0.866667         0.738889  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data frame from january\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load the data frame from january features\n",
    "df_jan = pd.read_parquet(\"../../data/features/ist_features_2025_01.parquet\")\n",
    "\n",
    "# drop rows with missing values\n",
    "n1 = len(df_jan)\n",
    "df_jan = df_jan.dropna()\n",
    "n2 = len(df_jan)\n",
    "print(f\"Dropped {(n1 - n2) / n1 * 100:.2f}% rows with missing values.\")\n",
    "\n",
    "# head\n",
    "df_jan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c900494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1744304 entries, 1 to 1796286\n",
      "Data columns (total 37 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   op_date                datetime64[ns]\n",
      " 1   trip_id                object        \n",
      " 2   stop_id                int64         \n",
      " 3   stop_name              object        \n",
      " 4   line_name              object        \n",
      " 5   vehicle_type           object        \n",
      " 6   additional_trip        object        \n",
      " 7   arrival_scheduled_dt   datetime64[ns]\n",
      " 8   arrival_observed_dt    datetime64[ns]\n",
      " 9   arrival_delay_minutes  float64       \n",
      " 10  is_delayed             int8          \n",
      " 11  hour_of_day            int32         \n",
      " 12  day_of_week            int32         \n",
      " 13  is_weekend             bool          \n",
      " 14  is_peak                bool          \n",
      " 15  vt_AG                  bool          \n",
      " 16  vt_ATZ                 bool          \n",
      " 17  vt_EC                  bool          \n",
      " 18  vt_EXT                 bool          \n",
      " 19  vt_IC                  bool          \n",
      " 20  vt_ICE                 bool          \n",
      " 21  vt_IR                  bool          \n",
      " 22  vt_NJ                  bool          \n",
      " 23  vt_PE                  bool          \n",
      " 24  vt_R                   bool          \n",
      " 25  vt_RB                  bool          \n",
      " 26  vt_RE                  bool          \n",
      " 27  vt_RJX                 bool          \n",
      " 28  vt_S                   bool          \n",
      " 29  vt_SN                  bool          \n",
      " 30  vt_TER                 bool          \n",
      " 31  vt_TGV                 bool          \n",
      " 32  latitude               float64       \n",
      " 33  longitude              float64       \n",
      " 34  connection_density     int64         \n",
      " 35  running_trip_delay     float64       \n",
      " 36  mean_stop_delay        float64       \n",
      "dtypes: bool(19), datetime64[ns](3), float64(5), int32(2), int64(2), int8(1), object(5)\n",
      "memory usage: 259.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4050e804",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split\n",
    "\n",
    "For these first baseline models, I do not use any particular processing techniques. I simply select the numerical exploitable features for predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e777f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bool columns to int\n",
    "bool_columns = df_jan.select_dtypes(include=['bool']).columns\n",
    "df_jan[bool_columns] = df_jan[bool_columns].astype(int)\n",
    "\n",
    "# X: only numerical columns except target: `arrival_delay_minutes`, `is_delayed`\n",
    "numerical_columns = df_jan.select_dtypes(include=[np.number]).columns.tolist()\n",
    "target_columns = ['arrival_delay_minutes', 'is_delayed']\n",
    "feature_columns = [col for col in numerical_columns if col not in target_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5db72",
   "metadata": {},
   "source": [
    "As stated above, I use the most minimalistic approach and do not use a validation window. I simply split the training data set (January) in **train set that accounts for roughly 70%** of the data set. To prevent data leakage, the **split is based on chronological order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7161825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPES OF DATASETS\n",
      "Training set shape: (1221012, 27) (1221012,)\n",
      "Testing set shape: (523292, 27) (523292,)\n",
      "\n",
      "TARGET VARIABLE STATISTICS\n",
      "Training set target mean: 4.99%\n",
      "Testing set target mean: 6.29%\n"
     ]
    }
   ],
   "source": [
    "# sort by arrival_scheduled_dt\n",
    "df_jan = df_jan.sort_values(by=['arrival_scheduled_dt'])\n",
    "\n",
    "# first 70% for training, last 30% for testing\n",
    "split_index = int(0.7 * len(df_jan))\n",
    "\n",
    "# training set\n",
    "X_train = df_jan[feature_columns].iloc[:split_index]\n",
    "y_train = df_jan['is_delayed'].iloc[:split_index]\n",
    "\n",
    "# testing set\n",
    "X_test = df_jan[feature_columns].iloc[split_index:]\n",
    "y_test = df_jan['is_delayed'].iloc[split_index:]\n",
    "\n",
    "\n",
    "\n",
    "# print shapes\n",
    "print(\"SHAPES OF DATASETS\")\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "print(\"\\nTARGET VARIABLE STATISTICS\")\n",
    "print(\"Training set target mean:\", f\"{100 * y_train.mean():.2f}%\")\n",
    "print(\"Testing set target mean:\", f\"{100 * y_test.mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6b46f",
   "metadata": {},
   "source": [
    "## 3. Baseline Models\n",
    "\n",
    "In this section, I run a few basic models to observe what kind of prediction I obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1ef51",
   "metadata": {},
   "source": [
    "### 3.0. Dummy Classifier\n",
    "\n",
    "This dummy classifier will simply predict the most common class, i.e 0 / \"not delayed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a4ed87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97    490381\n",
      "           1       0.00      0.00      0.00     32911\n",
      "\n",
      "    accuracy                           0.94    523292\n",
      "   macro avg       0.47      0.50      0.48    523292\n",
      "weighted avg       0.88      0.94      0.91    523292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")  # always predicts 0\n",
    "dummy.fit(X_train, y_train)\n",
    "print(classification_report(y_test, dummy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06104bf6",
   "metadata": {},
   "source": [
    "### 3.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d3ea885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97    490381\n",
      "           1       0.79      0.28      0.42     32911\n",
      "\n",
      "    accuracy                           0.95    523292\n",
      "   macro avg       0.87      0.64      0.69    523292\n",
      "weighted avg       0.94      0.95      0.94    523292\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[487881   2500]\n",
      " [ 23636   9275]]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# create and train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bd5cf",
   "metadata": {},
   "source": [
    "**Class 1 (delayed)**\n",
    "\n",
    "+ Precision 0.79: when the model predicts “delayed”, it’s right 79% of the time (good).\n",
    "+ Recall 0.28: it only catches 28% of actual delays (bad). It misses 72% of delays (lots of false negatives).\n",
    "\n",
    "Now I need to choose which metric I should favor. Ultimately, I have to strike a good balance between precision and recall so the f1 score is a decent metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9e8ba",
   "metadata": {},
   "source": [
    "### 3.2. Random Forest\n",
    "\n",
    "Now I run a tree-based model: the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "244db446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    490381\n",
      "           1       0.77      0.42      0.54     32911\n",
      "\n",
      "    accuracy                           0.96    523292\n",
      "   macro avg       0.86      0.71      0.76    523292\n",
      "weighted avg       0.95      0.96      0.95    523292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5d43a",
   "metadata": {},
   "source": [
    "The random forest is a clear improvement over the logistic regression. I must note however that the features have not been scaled yet and rf is usually scaling insensitive while logistic reg is not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34d0b8",
   "metadata": {},
   "source": [
    "### 3.3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfb1e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    490381\n",
      "           1       0.75      0.46      0.57     32911\n",
      "\n",
      "    accuracy                           0.96    523292\n",
      "   macro avg       0.86      0.73      0.77    523292\n",
      "weighted avg       0.95      0.96      0.95    523292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "hgb.fit(X_train, y_train)\n",
    "print(classification_report(y_test, hgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42844d28",
   "metadata": {},
   "source": [
    "This model roughly has the same performance than the rf. A slightly better f1 score for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa35de0",
   "metadata": {},
   "source": [
    "## 4. Error Driven EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16445c48",
   "metadata": {},
   "source": [
    "In this sub-section, I conduct an error driven EDA and aim to understand where my models fail. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8f0c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
